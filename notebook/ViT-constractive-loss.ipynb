{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dafd9c5",
   "metadata": {
    "_cell_guid": "7a5ce0f2-a8be-4b0a-8eee-f1528cd14f66",
    "_uuid": "19859d98-8792-41bd-b0f8-7d6c423ccc2c",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.005616,
     "end_time": "2024-06-08T03:04:57.953425",
     "exception": false,
     "start_time": "2024-06-08T03:04:57.947809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5291c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:04:57.965349Z",
     "iopub.status.busy": "2024-06-08T03:04:57.965059Z",
     "iopub.status.idle": "2024-06-08T03:05:05.542859Z",
     "shell.execute_reply": "2024-06-08T03:05:05.542077Z"
    },
    "papermill": {
     "duration": 7.586631,
     "end_time": "2024-06-08T03:05:05.545371",
     "exception": false,
     "start_time": "2024-06-08T03:04:57.958740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch import randint\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "mean = [0.2652, 0.2652, 0.2652]\n",
    "std = [0.1994, 0.1994, 0.1994]\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(p=0.3),\n",
    "        transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter(), ]), p=0.3),\n",
    "        transforms.RandomApply(torch.nn.ModuleList([transforms.GaussianBlur(kernel_size=3), ]), p=0.3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "class MammoCompDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_path=\"../VinDr_Mammo/physionet.org/files/vindr-mammo/1.0.0/images_png/\",\n",
    "                 metadata=\"../VinDr_Mammo/physionet.org/files/vindr-mammo/1.0.0/breast-level_annotations1.csv\",\n",
    "                 phase=\"train\",\n",
    "                 mode=\"binary_contrastive\",\n",
    "                 transform=None,\n",
    "                 datalen=100,\n",
    "                 certain=True,\n",
    "                 seed=None):\n",
    "        self.phase = phase\n",
    "        self.datalen = datalen  # Number of image pairs for training/testing\n",
    "        self.certain = certain\n",
    "        self.mode = mode\n",
    "        self.data_path = data_path\n",
    "        if (seed):\n",
    "            seed_everything(seed)\n",
    "\n",
    "        self.transform = data_transforms[self.phase] if (transform == None) else transform\n",
    "        data = pd.read_csv(metadata)\n",
    "        self.data = data.loc[data['split'] == phase].reset_index()\n",
    "        self.birads = []\n",
    "        for i in range(1, 6):\n",
    "            self.birads.append(self.data.loc[self.data['breast_birads'] == f'BI-RADS {i}'])\n",
    "        self.name_of_classes = [1, 2, 3, 4, 5]\n",
    "        self.len_of_classes = [len(self.birads[i].index) for i in range(5)]\n",
    "        self.paths1 = []\n",
    "        self.paths2 = []\n",
    "        self.listi1 = []\n",
    "        self.listi2 = []\n",
    "        self.complabels = []\n",
    "        curlen = 0\n",
    "        self.imagesinclass0 = self.birads[0]\n",
    "        seed_everything(seed)\n",
    "        while (curlen < self.datalen):\n",
    "            if (mode == 'multiclass_contrastive'):\n",
    "                if (random.randint(0, 1) == 0):\n",
    "                    i1 = random.randint(0, 4)\n",
    "                    i2 = random.randint(0, 4)\n",
    "                else:\n",
    "                    i1 = random.randint(0, 4)\n",
    "                    i2 = i1\n",
    "                # pickimageA = randint(0, lenofclass[random_pick_2class[0]], (1,))\n",
    "                self.listi1.append(i1)\n",
    "                self.listi2.append(i2)\n",
    "                self.paths1.append(self.get_path(self.birads[i1], randint(0, self.len_of_classes[i1], (1,))[0]))\n",
    "                self.paths2.append(self.get_path(self.birads[i2], randint(0, self.len_of_classes[i2], (1,))[0]))\n",
    "                self.complabels.append((i1 == i2) * 1)\n",
    "                curlen = curlen + 1\n",
    "            elif mode == 'binary_contrastive':\n",
    "                modee = random.randint(0, 3)\n",
    "                if (modee == 0):\n",
    "                    i1 = 0\n",
    "                    i2 = 0\n",
    "                elif (modee == 1):\n",
    "                    i1 = random.randint(1, 4)\n",
    "                    i2 = random.randint(1, 4)\n",
    "                elif (modee == 2):\n",
    "                    i1 = 0\n",
    "                    i2 = random.randint(1, 4)\n",
    "                else:\n",
    "                    i2 = 0\n",
    "                    i1 = random.randint(1, 4)\n",
    "                # pickimageA = randint(0, lenofclass[random_pick_2class[0]], (1,))\n",
    "                self.listi1.append(i1)\n",
    "                self.listi2.append(i2)\n",
    "                self.paths1.append(self.get_path(self.birads[i1], randint(0, self.len_of_classes[i1], (1,))[0]))\n",
    "                self.paths2.append(self.get_path(self.birads[i2], randint(0, self.len_of_classes[i2], (1,))[0]))\n",
    "                self.complabels.append((((i1 == 0) and (i2 == 0)) or ((i1 != 0) and (i2 != 0))) * 1)\n",
    "                curlen = curlen + 1\n",
    "            elif (mode == 'severity_comparison'):\n",
    "                i1 = random.randint(1, 4)\n",
    "                i2 = random.randint(1, 4)\n",
    "                # pickimageA = randint(0, lenofclass[random_pick_2class[0]], (1,))\n",
    "                self.listi1.append(i1)\n",
    "                self.listi2.append(i2)\n",
    "                self.paths1.append(self.get_path(self.birads[i1], randint(0, self.len_of_classes[i1], (1,))[0]))\n",
    "                self.paths2.append(self.get_path(self.birads[i2], randint(0, self.len_of_classes[i2], (1,))[0]))\n",
    "                self.complabels.append(((i1 > i2)) * 1)\n",
    "                curlen = curlen + 1\n",
    "            elif (mode == 'preference_contrastive'):\n",
    "                if (random.randint(0, 5) > 4):\n",
    "                    i1 = random.randint(1, 4)\n",
    "                    i2 = i1\n",
    "                else:\n",
    "                    i1 = random.randint(1, 4)\n",
    "                    i2 = random.randint(1, 4)\n",
    "                # pickimageA = randint(0, lenofclass[random_pick_2class[0]], (1,))\n",
    "                self.listi1.append(i1)\n",
    "                self.listi2.append(i2)\n",
    "                self.paths1.append(self.get_path(self.birads[i1], randint(0, self.len_of_classes[i1], (1,))[0]))\n",
    "                self.paths2.append(self.get_path(self.birads[i2], randint(0, self.len_of_classes[i2], (1,))[0]))\n",
    "                self.complabels.append((((i1 > i2)) * 1) if (i1 != i2) else 2)\n",
    "                curlen = curlen + 1\n",
    "            else:\n",
    "                assert False, f\"No mode {mode} found, please try multiclass_contrastive or binary_contrastive\"\n",
    "\n",
    "    def get_score(self, data, index):\n",
    "        birads = data['breast_birads'].iloc[index.item()]\n",
    "        score = eval(birads[-1])\n",
    "        return score\n",
    "\n",
    "    def get_path(self, data, index):\n",
    "\n",
    "        image_name = data['image_id'].iloc[index.item()]\n",
    "        study_id = data['study_id'].iloc[index.item()]\n",
    "        image_path = os.path.join(self.data_path, study_id + '/' + image_name + '.png')\n",
    "        return (image_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imageA = cv2.imread(self.paths1[index])\n",
    "        imageB = cv2.imread(self.paths2[index])\n",
    "\n",
    "        label = self.complabels[index]\n",
    "\n",
    "        imageA = self.transform(imageA)\n",
    "        imageB = self.transform(imageB)\n",
    "        if self.mode == 'severity_comparison':\n",
    "            ref_img = self.get_ref_images()\n",
    "            return (imageA, imageB), ref_img, label, (self.listi1[index], self.listi2[index])\n",
    "        else:\n",
    "            return (imageA, imageB), label, (self.listi1[index], self.listi2[index])\n",
    "\n",
    "    def get_ref_images(self):\n",
    "        ref_img = self.get_path(self.imagesinclass0, randint(0, len(self.imagesinclass0), (1,))[0])\n",
    "        ref_img = cv2.imread(ref_img)\n",
    "        ref_img = self.transform(ref_img)\n",
    "\n",
    "        return ref_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datalen\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5731d78",
   "metadata": {
    "papermill": {
     "duration": 0.005093,
     "end_time": "2024-06-08T03:05:05.555986",
     "exception": false,
     "start_time": "2024-06-08T03:05:05.550893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef787d5d",
   "metadata": {
    "papermill": {
     "duration": 0.004634,
     "end_time": "2024-06-08T03:05:05.565683",
     "exception": false,
     "start_time": "2024-06-08T03:05:05.561049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1 - ViT Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5adf5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:05:05.577549Z",
     "iopub.status.busy": "2024-06-08T03:05:05.577152Z",
     "iopub.status.idle": "2024-06-08T03:05:07.000530Z",
     "shell.execute_reply": "2024-06-08T03:05:06.999561Z"
    },
    "papermill": {
     "duration": 1.43239,
     "end_time": "2024-06-08T03:05:07.003058",
     "exception": false,
     "start_time": "2024-06-08T03:05:05.570668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# SimMIM\n",
    "# Copyright (c) 2021 Microsoft\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Based on BEIT code bases (https://github.com/microsoft/unilm/tree/master/beit)\n",
    "# Written by Yutong Lin, Zhenda Xie\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        # x = self.drop(x)\n",
    "        # comment out this for the orignal BERT implement\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "            self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0.,\n",
    "            proj_drop=0., window_size=None, attn_head_dim=None):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        if attn_head_dim is not None:\n",
    "            head_dim = attn_head_dim\n",
    "        all_head_dim = head_dim * self.num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, all_head_dim * 3, bias=False)\n",
    "        if qkv_bias:\n",
    "            self.q_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
    "            self.v_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
    "        else:\n",
    "            self.q_bias = None\n",
    "            self.v_bias = None\n",
    "\n",
    "        if window_size:\n",
    "            self.window_size = window_size\n",
    "            # cls to token & token to cls & cls to cls\n",
    "            self.num_relative_distance = (2 * window_size[0] - 1) * (2 * window_size[1] - 1) + 3\n",
    "            self.relative_position_bias_table = nn.Parameter(\n",
    "                torch.zeros(self.num_relative_distance, num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "            # get pair-wise relative position index for each token inside the window\n",
    "            coords_h = torch.arange(window_size[0])\n",
    "            coords_w = torch.arange(window_size[1])\n",
    "            coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "            coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "            relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "            relative_coords[:, :, 0] += window_size[0] - 1  # shift to start from 0\n",
    "            relative_coords[:, :, 1] += window_size[1] - 1\n",
    "            relative_coords[:, :, 0] *= 2 * window_size[1] - 1\n",
    "            relative_position_index = \\\n",
    "                torch.zeros(size=(window_size[0] * window_size[1] + 1,) * 2, dtype=relative_coords.dtype)\n",
    "            relative_position_index[1:, 1:] = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "            relative_position_index[0, 0:] = self.num_relative_distance - 3\n",
    "            relative_position_index[0:, 0] = self.num_relative_distance - 2\n",
    "            relative_position_index[0, 0] = self.num_relative_distance - 1\n",
    "\n",
    "            self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "        else:\n",
    "            self.window_size = None\n",
    "            self.relative_position_bias_table = None\n",
    "            self.relative_position_index = None\n",
    "\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(all_head_dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x, rel_pos_bias=None):\n",
    "        B, N, C = x.shape\n",
    "        qkv_bias = None\n",
    "        if self.q_bias is not None:\n",
    "            qkv_bias = torch.cat((self.q_bias, torch.zeros_like(self.v_bias, requires_grad=False), self.v_bias))\n",
    "        qkv = F.linear(input=x, weight=self.qkv.weight, bias=qkv_bias)\n",
    "        qkv = qkv.reshape(B, N, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        if self.relative_position_bias_table is not None:\n",
    "            relative_position_bias = \\\n",
    "                self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "                    self.window_size[0] * self.window_size[1] + 1,\n",
    "                    self.window_size[0] * self.window_size[1] + 1, -1)  # Wh*Ww,Wh*Ww,nH\n",
    "            relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "            attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if rel_pos_bias is not None:\n",
    "            attn = attn + rel_pos_bias\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, -1)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., init_values=None, act_layer=nn.GELU, norm_layer=nn.LayerNorm,\n",
    "                 window_size=None, attn_head_dim=None):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "            attn_drop=attn_drop, proj_drop=drop, window_size=window_size, attn_head_dim=attn_head_dim)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "        if init_values is not None:\n",
    "            self.gamma_1 = nn.Parameter(init_values * torch.ones((dim)), requires_grad=True)\n",
    "            self.gamma_2 = nn.Parameter(init_values * torch.ones((dim)), requires_grad=True)\n",
    "        else:\n",
    "            self.gamma_1, self.gamma_2 = None, None\n",
    "\n",
    "    def forward(self, x, rel_pos_bias=None):\n",
    "        if self.gamma_1 is None:\n",
    "            x = x + self.drop_path(self.attn(self.norm1(x), rel_pos_bias=rel_pos_bias))\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        else:\n",
    "            x = x + self.drop_path(self.gamma_1 * self.attn(self.norm1(x), rel_pos_bias=rel_pos_bias))\n",
    "            x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.patch_shape = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        B, C, H, W = x.shape\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RelativePositionBias(nn.Module):\n",
    "\n",
    "    def __init__(self, window_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.num_relative_distance = (2 * window_size[0] - 1) * (2 * window_size[1] - 1) + 3\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros(self.num_relative_distance, num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "        # cls to token & token 2 cls & cls to cls\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(window_size[0])\n",
    "        coords_w = torch.arange(window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += window_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * window_size[1] - 1\n",
    "        relative_position_index = \\\n",
    "            torch.zeros(size=(window_size[0] * window_size[1] + 1,) * 2, dtype=relative_coords.dtype)\n",
    "        relative_position_index[1:, 1:] = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        relative_position_index[0, 0:] = self.num_relative_distance - 3\n",
    "        relative_position_index[0:, 0] = self.num_relative_distance - 2\n",
    "        relative_position_index[0, 0] = self.num_relative_distance - 1\n",
    "\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "    def forward(self):\n",
    "        relative_position_bias = \\\n",
    "            self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "                self.window_size[0] * self.window_size[1] + 1,\n",
    "                self.window_size[0] * self.window_size[1] + 1, -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        return relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, depth=12,\n",
    "                 num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "                 drop_path_rate=0., norm_layer=nn.LayerNorm, init_values=None,\n",
    "                 use_abs_pos_emb=True, use_rel_pos_bias=False, use_shared_rel_pos_bias=False,\n",
    "                 use_mean_pooling=True, init_scale=0.001):\n",
    "        super().__init__()\n",
    "        self.num_features = self.embed_dim = embed_dim\n",
    "        self.patch_size = patch_size\n",
    "        self.in_chans = in_chans\n",
    "\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        if use_abs_pos_emb:\n",
    "            self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        else:\n",
    "            self.pos_embed = None\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        if use_shared_rel_pos_bias:\n",
    "            self.rel_pos_bias = RelativePositionBias(window_size=self.patch_embed.patch_shape, num_heads=num_heads)\n",
    "        else:\n",
    "            self.rel_pos_bias = None\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        self.use_rel_pos_bias = use_rel_pos_bias\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer,\n",
    "                init_values=init_values, window_size=self.patch_embed.patch_shape if use_rel_pos_bias else None)\n",
    "            for i in range(depth)])\n",
    "        self.norm = nn.Identity() if use_mean_pooling else norm_layer(embed_dim)\n",
    "        self.fc_norm = norm_layer(embed_dim) if use_mean_pooling else None\n",
    "\n",
    "        if self.pos_embed is not None:\n",
    "            self._trunc_normal_(self.pos_embed, std=.02)\n",
    "        self._trunc_normal_(self.cls_token, std=.02)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.fix_init_weight()\n",
    "\n",
    "    def _trunc_normal_(self, tensor, mean=0., std=1.):\n",
    "        trunc_normal_(tensor, mean=mean, std=std)\n",
    "\n",
    "    def fix_init_weight(self):\n",
    "        def rescale(param, layer_id):\n",
    "            param.div_(math.sqrt(2.0 * layer_id))\n",
    "\n",
    "        for layer_id, layer in enumerate(self.blocks):\n",
    "            rescale(layer.attn.proj.weight.data, layer_id + 1)\n",
    "            rescale(layer.mlp.fc2.weight.data, layer_id + 1)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            self._trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            self._trunc_normal_(m.weight, std=.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def get_num_layers(self):\n",
    "        return len(self.blocks)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        if self.pos_embed is not None:\n",
    "            x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        rel_pos_bias = self.rel_pos_bias() if self.rel_pos_bias is not None else None\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x, rel_pos_bias=rel_pos_bias)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        if self.fc_norm is not None:\n",
    "            t = x[:, 1:, :]\n",
    "            return self.fc_norm(t.mean(1))\n",
    "        else:\n",
    "            return x[:, 0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_vit(config):\n",
    "    model = VisionTransformer(\n",
    "        img_size=config.DATA.IMG_SIZE,\n",
    "        patch_size=config.MODEL.VIT.PATCH_SIZE,\n",
    "        in_chans=config.MODEL.VIT.IN_CHANS,\n",
    "        embed_dim=config.MODEL.VIT.EMBED_DIM,\n",
    "        depth=config.MODEL.VIT.DEPTH,\n",
    "        num_heads=config.MODEL.VIT.NUM_HEADS,\n",
    "        mlp_ratio=config.MODEL.VIT.MLP_RATIO,\n",
    "        qkv_bias=config.MODEL.VIT.QKV_BIAS,\n",
    "        drop_rate=config.MODEL.DROP_RATE,\n",
    "        drop_path_rate=config.MODEL.DROP_PATH_RATE,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    "        init_values=config.MODEL.VIT.INIT_VALUES,\n",
    "        use_abs_pos_emb=config.MODEL.VIT.USE_APE,\n",
    "        use_rel_pos_bias=config.MODEL.VIT.USE_RPB,\n",
    "        use_shared_rel_pos_bias=config.MODEL.VIT.USE_SHARED_RPB,\n",
    "        use_mean_pooling=config.MODEL.VIT.USE_MEAN_POOLING)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01a739a",
   "metadata": {
    "papermill": {
     "duration": 0.005124,
     "end_time": "2024-06-08T03:05:07.013888",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.008764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2 - SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d8ba57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:05:07.025793Z",
     "iopub.status.busy": "2024-06-08T03:05:07.025494Z",
     "iopub.status.idle": "2024-06-08T03:05:07.034488Z",
     "shell.execute_reply": "2024-06-08T03:05:07.033714Z"
    },
    "papermill": {
     "duration": 0.017377,
     "end_time": "2024-06-08T03:05:07.036477",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.019100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "\n",
    "    def __init__(self, base_model, config, out_dim):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.resnet_dict = {\"vit\": build_vit(config),\n",
    "                            \"swin\": None}\n",
    "\n",
    "        self.backbone = self._get_basemodel(base_model)\n",
    "        dim_mlp = self.backbone.embed_dim\n",
    "\n",
    "        # add mlp projection head\n",
    "        self.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp),\n",
    "                                nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                nn.Linear(dim_mlp, 512),\n",
    "                                nn.ReLU(),\n",
    "                                torch.nn.Dropout(0.1),\n",
    "                                nn.Linear(512, out_dim)\n",
    "                                )\n",
    "\n",
    "    def _get_basemodel(self, model_name):\n",
    "        try:\n",
    "            model = self.resnet_dict[model_name]\n",
    "        except Exception:\n",
    "            print(\"Invalid backbone architecture. Check the config file and pass one of: Vit or Swin Transformer\")\n",
    "        else:\n",
    "            return model\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c6eb8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:05:07.047911Z",
     "iopub.status.busy": "2024-06-08T03:05:07.047627Z",
     "iopub.status.idle": "2024-06-08T03:05:07.053528Z",
     "shell.execute_reply": "2024-06-08T03:05:07.052770Z"
    },
    "papermill": {
     "duration": 0.013867,
     "end_time": "2024-06-08T03:05:07.055497",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.041630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimCLRModelPipeline(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(SimCLRModelPipeline, self).__init__()\n",
    "        # note that model requires 3 input channels, will repeat grayscale image x3\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        output = self.encoder(x)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded5079",
   "metadata": {
    "papermill": {
     "duration": 0.004917,
     "end_time": "2024-06-08T03:05:07.065747",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.060830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f29dac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:05:07.076994Z",
     "iopub.status.busy": "2024-06-08T03:05:07.076720Z",
     "iopub.status.idle": "2024-06-08T03:05:07.083313Z",
     "shell.execute_reply": "2024-06-08T03:05:07.082548Z"
    },
    "papermill": {
     "duration": 0.01434,
     "end_time": "2024-06-08T03:05:07.085137",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.070797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn, pow, mean, clamp\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    Modified from: https://hackernoon.com/facial-similarity-with-siamese-networks-in-pytorch-9642aa9db2f7\n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "        # loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "        #                               (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        \n",
    "        cosine_distance = nn.functional.cosine_similarity(output1, output2)\n",
    "        loss_contrastive = mean((1-label) * pow(cosine_distance, 2) +\n",
    "                                      (label) * pow(clamp(self.margin - cosine_distance, min=0.0), 2))\n",
    "        # loss_contrastive =  torch.nn.NLLLoss()(cosine_distance)\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf5526",
   "metadata": {
    "papermill": {
     "duration": 0.004943,
     "end_time": "2024-06-08T03:05:07.094892",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.089949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef9cab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:05:07.106530Z",
     "iopub.status.busy": "2024-06-08T03:05:07.105830Z",
     "iopub.status.idle": "2024-06-08T03:05:07.125011Z",
     "shell.execute_reply": "2024-06-08T03:05:07.124235Z"
    },
    "papermill": {
     "duration": 0.026929,
     "end_time": "2024-06-08T03:05:07.126979",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.100050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "\n",
    "\n",
    "def train_model(model, train_dataset, val_dataset, checkpoint_folder, num_epochs=10, batch_size=32,\n",
    "                learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Train the model using the provided datasets.\n",
    "\n",
    "    Args:\n",
    "    - model: The model to be trained\n",
    "    - train_dataset: Dataset for training\n",
    "    - val_dataset: Dataset for validation\n",
    "    - checkpoint_folder: Folder to store checkpoints\n",
    "    - num_epochs: Number of epochs for training\n",
    "    - batch_size: Batch size for training\n",
    "    - learning_rate: Learning rate for optimization\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained model\n",
    "    - train_losses: List of training losses\n",
    "    - val_losses: List of validation losses\n",
    "    \"\"\"\n",
    "    # Create the checkpoint folder if it doesn't exist\n",
    "    if not os.path.exists(checkpoint_folder):\n",
    "        os.makedirs(checkpoint_folder)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Device: {device}\")\n",
    "    # Define data loaders for training and validation\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = ContrastiveLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    # Lists to store training and validation losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Variables to keep track of the best model and its performance\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    model = model.to(device)\n",
    "    print(\"Training started...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"*\" * 100)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}]:\")\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for i, (inputs, labels, _) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            inputA = inputs[0].to(device)\n",
    "            inputB = inputs[1].to(device)\n",
    "            labels = labels.to(device)\n",
    "            output1, output2 = model(inputA, inputB)\n",
    "            # Compute loss\n",
    "            loss = criterion(output1, output2, labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "            if i % 200 == 0:\n",
    "                print(f\"\\t Batch [{i}/{len(train_loader)}], Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Compute average training loss for the epoch\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels, _) in enumerate(val_loader):\n",
    "                inputA = inputs[0].to(device)\n",
    "                inputB = inputs[1].to(device)\n",
    "                labels = labels.to(device)\n",
    "                output1, output2 = model(inputA, inputB)\n",
    "                loss = criterion(output1, output2, labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    print(\n",
    "                        f\"Epoch [{epoch + 1}/{num_epochs}], Validation Batch [{i}/{len(val_loader)}], Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Compute average validation loss for the epoch\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "\n",
    "        # Save the model checkpoint for every epoch (last model)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': epoch_val_loss\n",
    "        }, os.path.join(checkpoint_folder, f'last.pt'))\n",
    "\n",
    "        # Save the best model checkpoint based on validation loss\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': best_model_state,\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': best_val_loss\n",
    "            }, os.path.join(checkpoint_folder, f'best.pt'))\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Validation, Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "        print(\"*\" * 100)\n",
    "        scheduler.step()\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    return model, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cea13f",
   "metadata": {
    "papermill": {
     "duration": 0.004697,
     "end_time": "2024-06-08T03:05:07.136685",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.131988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b2bbde4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:05:07.147656Z",
     "iopub.status.busy": "2024-06-08T03:05:07.147339Z",
     "iopub.status.idle": "2024-06-08T03:05:07.155167Z",
     "shell.execute_reply": "2024-06-08T03:05:07.154318Z"
    },
    "papermill": {
     "duration": 0.01538,
     "end_time": "2024-06-08T03:05:07.157078",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.141698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "config = {\n",
    "    \"annotation_data_path\": \"/kaggle/input/mammo-224-224-ver2/split_data.csv\",\n",
    "    \"image_folder_path\": \"/kaggle/input/mammo-224-224-ver2/Processed_Images\",\n",
    "    \"model_encoder\": \"vit\",\n",
    "    \"data_length\": 10000,\n",
    "    \"embedding_dim\": 256, \n",
    "    \"learning_rate\":0.1,\n",
    "    \"num_epoch\": 50,\n",
    "    \"batch_size\": 8,\n",
    "    \"model_config\": \"/kaggle/input/vit-config/simmim_pretrain__vit_base__img224__800ep.yaml\",\n",
    "    \"checkpoint\": \"/kaggle/input/pre-trained-encoder-model/pytorch/viiy_224_800e/1/vit_base_image224_800ep.pt\",\n",
    "    \"checkpoint_folder\": f\"/kaggle/working/weights_setting2/resnet50BasedModel_{now}\"\n",
    "}\n",
    "\n",
    "class AttrDict(dict):\n",
    "    \"\"\"A dictionary that allows for attribute-style access.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        for key, value in self.items():\n",
    "            if isinstance(value, dict):\n",
    "                value = AttrDict(value)\n",
    "            self[key] = value\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        try:\n",
    "            return self[item]\n",
    "        except KeyError:\n",
    "            raise AttributeError(f\"'AttrDict' object has no attribute '{item}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dbb67b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:05:07.168172Z",
     "iopub.status.busy": "2024-06-08T03:05:07.167889Z",
     "iopub.status.idle": "2024-06-08T14:48:53.578201Z",
     "shell.execute_reply": "2024-06-08T14:48:53.577294Z"
    },
    "papermill": {
     "duration": 42226.46282,
     "end_time": "2024-06-08T14:48:53.624898",
     "exception": false,
     "start_time": "2024-06-08T03:05:07.162078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: /kaggle/input/pre-trained-encoder-model/pytorch/viiy_224_800e/1/vit_base_image224_800ep.pt\n",
      "Device: cuda\n",
      "Training started...\n",
      "****************************************************************************************************\n",
      "Epoch [1/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0384\n",
      "\t Batch [200/1250], Train Loss: 0.9992\n",
      "\t Batch [400/1250], Train Loss: 0.9988\n",
      "\t Batch [600/1250], Train Loss: 0.9994\n",
      "\t Batch [800/1250], Train Loss: 0.9987\n",
      "\t Batch [1000/1250], Train Loss: 0.9981\n",
      "\t Batch [1200/1250], Train Loss: 1.0016\n",
      "Epoch [1/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [1/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0002, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [2/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9964\n",
      "\t Batch [200/1250], Train Loss: 0.9999\n",
      "\t Batch [400/1250], Train Loss: 0.9996\n",
      "\t Batch [600/1250], Train Loss: 1.0011\n",
      "\t Batch [800/1250], Train Loss: 0.9996\n",
      "\t Batch [1000/1250], Train Loss: 1.0032\n",
      "\t Batch [1200/1250], Train Loss: 0.9916\n",
      "Epoch [2/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [2/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [3/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0008\n",
      "\t Batch [200/1250], Train Loss: 1.0034\n",
      "\t Batch [400/1250], Train Loss: 1.0022\n",
      "\t Batch [600/1250], Train Loss: 1.0006\n",
      "\t Batch [800/1250], Train Loss: 0.9989\n",
      "\t Batch [1000/1250], Train Loss: 1.0012\n",
      "\t Batch [1200/1250], Train Loss: 0.9987\n",
      "Epoch [3/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [3/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [4/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0001\n",
      "\t Batch [200/1250], Train Loss: 1.0039\n",
      "\t Batch [400/1250], Train Loss: 0.9988\n",
      "\t Batch [600/1250], Train Loss: 1.0001\n",
      "\t Batch [800/1250], Train Loss: 0.9959\n",
      "\t Batch [1000/1250], Train Loss: 1.0016\n",
      "\t Batch [1200/1250], Train Loss: 0.9995\n",
      "Epoch [4/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [4/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [5/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0009\n",
      "\t Batch [200/1250], Train Loss: 0.9980\n",
      "\t Batch [400/1250], Train Loss: 1.0030\n",
      "\t Batch [600/1250], Train Loss: 0.9940\n",
      "\t Batch [800/1250], Train Loss: 1.0165\n",
      "\t Batch [1000/1250], Train Loss: 0.9981\n",
      "\t Batch [1200/1250], Train Loss: 1.0072\n",
      "Epoch [5/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [5/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [6/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9982\n",
      "\t Batch [200/1250], Train Loss: 1.0166\n",
      "\t Batch [400/1250], Train Loss: 1.0114\n",
      "\t Batch [600/1250], Train Loss: 1.0012\n",
      "\t Batch [800/1250], Train Loss: 1.0025\n",
      "\t Batch [1000/1250], Train Loss: 1.0054\n",
      "\t Batch [1200/1250], Train Loss: 1.0005\n",
      "Epoch [6/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [6/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [7/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9943\n",
      "\t Batch [200/1250], Train Loss: 0.9986\n",
      "\t Batch [400/1250], Train Loss: 1.0055\n",
      "\t Batch [600/1250], Train Loss: 1.0084\n",
      "\t Batch [800/1250], Train Loss: 1.0075\n",
      "\t Batch [1000/1250], Train Loss: 0.9920\n",
      "\t Batch [1200/1250], Train Loss: 1.0007\n",
      "Epoch [7/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [7/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [8/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9989\n",
      "\t Batch [200/1250], Train Loss: 0.9967\n",
      "\t Batch [400/1250], Train Loss: 1.0039\n",
      "\t Batch [600/1250], Train Loss: 1.0019\n",
      "\t Batch [800/1250], Train Loss: 0.9999\n",
      "\t Batch [1000/1250], Train Loss: 1.0109\n",
      "\t Batch [1200/1250], Train Loss: 0.9970\n",
      "Epoch [8/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [8/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0001, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [9/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0004\n",
      "\t Batch [200/1250], Train Loss: 1.0043\n",
      "\t Batch [400/1250], Train Loss: 1.0136\n",
      "\t Batch [600/1250], Train Loss: 0.9880\n",
      "\t Batch [800/1250], Train Loss: 1.0105\n",
      "\t Batch [1000/1250], Train Loss: 1.0001\n",
      "\t Batch [1200/1250], Train Loss: 0.9994\n",
      "Epoch [9/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [9/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [10/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0052\n",
      "\t Batch [200/1250], Train Loss: 0.9943\n",
      "\t Batch [400/1250], Train Loss: 1.0024\n",
      "\t Batch [600/1250], Train Loss: 0.9968\n",
      "\t Batch [800/1250], Train Loss: 1.0026\n",
      "\t Batch [1000/1250], Train Loss: 1.0008\n",
      "\t Batch [1200/1250], Train Loss: 0.9994\n",
      "Epoch [10/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [10/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [11/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0023\n",
      "\t Batch [200/1250], Train Loss: 1.0036\n",
      "\t Batch [400/1250], Train Loss: 0.9995\n",
      "\t Batch [600/1250], Train Loss: 1.0016\n",
      "\t Batch [800/1250], Train Loss: 0.9968\n",
      "\t Batch [1000/1250], Train Loss: 0.9951\n",
      "\t Batch [1200/1250], Train Loss: 0.9996\n",
      "Epoch [11/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [11/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [12/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9960\n",
      "\t Batch [200/1250], Train Loss: 1.0002\n",
      "\t Batch [400/1250], Train Loss: 0.9970\n",
      "\t Batch [600/1250], Train Loss: 0.9852\n",
      "\t Batch [800/1250], Train Loss: 1.0056\n",
      "\t Batch [1000/1250], Train Loss: 1.0074\n",
      "\t Batch [1200/1250], Train Loss: 0.9943\n",
      "Epoch [12/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [12/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9998, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [13/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9918\n",
      "\t Batch [200/1250], Train Loss: 1.0119\n",
      "\t Batch [400/1250], Train Loss: 1.0035\n",
      "\t Batch [600/1250], Train Loss: 0.9941\n",
      "\t Batch [800/1250], Train Loss: 0.9921\n",
      "\t Batch [1000/1250], Train Loss: 1.0109\n",
      "\t Batch [1200/1250], Train Loss: 1.0030\n",
      "Epoch [13/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [13/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9997, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [14/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9882\n",
      "\t Batch [200/1250], Train Loss: 0.9987\n",
      "\t Batch [400/1250], Train Loss: 0.9993\n",
      "\t Batch [600/1250], Train Loss: 0.9870\n",
      "\t Batch [800/1250], Train Loss: 0.9943\n",
      "\t Batch [1000/1250], Train Loss: 1.0113\n",
      "\t Batch [1200/1250], Train Loss: 1.0007\n",
      "Epoch [14/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [14/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9998, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [15/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9949\n",
      "\t Batch [200/1250], Train Loss: 0.9927\n",
      "\t Batch [400/1250], Train Loss: 1.0058\n",
      "\t Batch [600/1250], Train Loss: 1.0158\n",
      "\t Batch [800/1250], Train Loss: 1.0107\n",
      "\t Batch [1000/1250], Train Loss: 1.0122\n",
      "\t Batch [1200/1250], Train Loss: 0.9968\n",
      "Epoch [15/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [15/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0001, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [16/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0019\n",
      "\t Batch [200/1250], Train Loss: 1.0072\n",
      "\t Batch [400/1250], Train Loss: 1.0081\n",
      "\t Batch [600/1250], Train Loss: 1.0105\n",
      "\t Batch [800/1250], Train Loss: 0.9914\n",
      "\t Batch [1000/1250], Train Loss: 1.0028\n",
      "\t Batch [1200/1250], Train Loss: 0.9924\n",
      "Epoch [16/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [16/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [17/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0064\n",
      "\t Batch [200/1250], Train Loss: 1.0084\n",
      "\t Batch [400/1250], Train Loss: 0.9981\n",
      "\t Batch [600/1250], Train Loss: 0.9992\n",
      "\t Batch [800/1250], Train Loss: 0.9955\n",
      "\t Batch [1000/1250], Train Loss: 1.0128\n",
      "\t Batch [1200/1250], Train Loss: 1.0002\n",
      "Epoch [17/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [17/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [18/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0037\n",
      "\t Batch [200/1250], Train Loss: 0.9995\n",
      "\t Batch [400/1250], Train Loss: 1.0011\n",
      "\t Batch [600/1250], Train Loss: 0.9947\n",
      "\t Batch [800/1250], Train Loss: 0.9987\n",
      "\t Batch [1000/1250], Train Loss: 1.0008\n",
      "\t Batch [1200/1250], Train Loss: 0.9910\n",
      "Epoch [18/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [18/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [19/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9937\n",
      "\t Batch [200/1250], Train Loss: 0.9979\n",
      "\t Batch [400/1250], Train Loss: 0.9958\n",
      "\t Batch [600/1250], Train Loss: 1.0035\n",
      "\t Batch [800/1250], Train Loss: 1.0047\n",
      "\t Batch [1000/1250], Train Loss: 0.9993\n",
      "\t Batch [1200/1250], Train Loss: 0.9999\n",
      "Epoch [19/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [19/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [20/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9940\n",
      "\t Batch [200/1250], Train Loss: 0.9984\n",
      "\t Batch [400/1250], Train Loss: 1.0023\n",
      "\t Batch [600/1250], Train Loss: 0.9966\n",
      "\t Batch [800/1250], Train Loss: 1.0014\n",
      "\t Batch [1000/1250], Train Loss: 0.9948\n",
      "\t Batch [1200/1250], Train Loss: 1.0057\n",
      "Epoch [20/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [20/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [21/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9966\n",
      "\t Batch [200/1250], Train Loss: 0.9986\n",
      "\t Batch [400/1250], Train Loss: 1.0085\n",
      "\t Batch [600/1250], Train Loss: 1.0003\n",
      "\t Batch [800/1250], Train Loss: 0.9990\n",
      "\t Batch [1000/1250], Train Loss: 0.9945\n",
      "\t Batch [1200/1250], Train Loss: 0.9973\n",
      "Epoch [21/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [21/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [22/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0110\n",
      "\t Batch [200/1250], Train Loss: 0.9974\n",
      "\t Batch [400/1250], Train Loss: 0.9956\n",
      "\t Batch [600/1250], Train Loss: 1.0044\n",
      "\t Batch [800/1250], Train Loss: 0.9963\n",
      "\t Batch [1000/1250], Train Loss: 0.9962\n",
      "\t Batch [1200/1250], Train Loss: 0.9963\n",
      "Epoch [22/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [22/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [23/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0014\n",
      "\t Batch [200/1250], Train Loss: 0.9994\n",
      "\t Batch [400/1250], Train Loss: 1.0002\n",
      "\t Batch [600/1250], Train Loss: 1.0031\n",
      "\t Batch [800/1250], Train Loss: 1.0078\n",
      "\t Batch [1000/1250], Train Loss: 0.9981\n",
      "\t Batch [1200/1250], Train Loss: 0.9978\n",
      "Epoch [23/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [23/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [24/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0010\n",
      "\t Batch [200/1250], Train Loss: 0.9936\n",
      "\t Batch [400/1250], Train Loss: 0.9955\n",
      "\t Batch [600/1250], Train Loss: 1.0111\n",
      "\t Batch [800/1250], Train Loss: 1.0021\n",
      "\t Batch [1000/1250], Train Loss: 0.9977\n",
      "\t Batch [1200/1250], Train Loss: 0.9988\n",
      "Epoch [24/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [24/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [25/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9959\n",
      "\t Batch [200/1250], Train Loss: 1.0004\n",
      "\t Batch [400/1250], Train Loss: 0.9965\n",
      "\t Batch [600/1250], Train Loss: 1.0061\n",
      "\t Batch [800/1250], Train Loss: 0.9999\n",
      "\t Batch [1000/1250], Train Loss: 0.9946\n",
      "\t Batch [1200/1250], Train Loss: 0.9947\n",
      "Epoch [25/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [25/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [26/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9957\n",
      "\t Batch [200/1250], Train Loss: 1.0012\n",
      "\t Batch [400/1250], Train Loss: 0.9985\n",
      "\t Batch [600/1250], Train Loss: 1.0096\n",
      "\t Batch [800/1250], Train Loss: 0.9992\n",
      "\t Batch [1000/1250], Train Loss: 1.0031\n",
      "\t Batch [1200/1250], Train Loss: 1.0005\n",
      "Epoch [26/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [26/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [27/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0010\n",
      "\t Batch [200/1250], Train Loss: 0.9955\n",
      "\t Batch [400/1250], Train Loss: 0.9998\n",
      "\t Batch [600/1250], Train Loss: 1.0111\n",
      "\t Batch [800/1250], Train Loss: 1.0013\n",
      "\t Batch [1000/1250], Train Loss: 1.0054\n",
      "\t Batch [1200/1250], Train Loss: 0.9943\n",
      "Epoch [27/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [27/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [28/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9964\n",
      "\t Batch [200/1250], Train Loss: 0.9993\n",
      "\t Batch [400/1250], Train Loss: 0.9955\n",
      "\t Batch [600/1250], Train Loss: 0.9956\n",
      "\t Batch [800/1250], Train Loss: 0.9971\n",
      "\t Batch [1000/1250], Train Loss: 0.9993\n",
      "\t Batch [1200/1250], Train Loss: 0.9977\n",
      "Epoch [28/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [28/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9998, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [29/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9965\n",
      "\t Batch [200/1250], Train Loss: 0.9986\n",
      "\t Batch [400/1250], Train Loss: 1.0019\n",
      "\t Batch [600/1250], Train Loss: 0.9920\n",
      "\t Batch [800/1250], Train Loss: 0.9958\n",
      "\t Batch [1000/1250], Train Loss: 1.0008\n",
      "\t Batch [1200/1250], Train Loss: 0.9981\n",
      "Epoch [29/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [29/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [30/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9962\n",
      "\t Batch [200/1250], Train Loss: 0.9992\n",
      "\t Batch [400/1250], Train Loss: 0.9973\n",
      "\t Batch [600/1250], Train Loss: 1.0016\n",
      "\t Batch [800/1250], Train Loss: 0.9998\n",
      "\t Batch [1000/1250], Train Loss: 1.0053\n",
      "\t Batch [1200/1250], Train Loss: 0.9937\n",
      "Epoch [30/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [30/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [31/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9994\n",
      "\t Batch [200/1250], Train Loss: 1.0034\n",
      "\t Batch [400/1250], Train Loss: 0.9954\n",
      "\t Batch [600/1250], Train Loss: 1.0061\n",
      "\t Batch [800/1250], Train Loss: 1.0016\n",
      "\t Batch [1000/1250], Train Loss: 0.9977\n",
      "\t Batch [1200/1250], Train Loss: 1.0075\n",
      "Epoch [31/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [31/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0001, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [32/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0036\n",
      "\t Batch [200/1250], Train Loss: 1.0018\n",
      "\t Batch [400/1250], Train Loss: 1.0020\n",
      "\t Batch [600/1250], Train Loss: 0.9976\n",
      "\t Batch [800/1250], Train Loss: 1.0127\n",
      "\t Batch [1000/1250], Train Loss: 1.0006\n",
      "\t Batch [1200/1250], Train Loss: 1.0018\n",
      "Epoch [32/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [32/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9998, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [33/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9943\n",
      "\t Batch [200/1250], Train Loss: 1.0017\n",
      "\t Batch [400/1250], Train Loss: 1.0085\n",
      "\t Batch [600/1250], Train Loss: 1.0062\n",
      "\t Batch [800/1250], Train Loss: 0.9920\n",
      "\t Batch [1000/1250], Train Loss: 0.9937\n",
      "\t Batch [1200/1250], Train Loss: 0.9982\n",
      "Epoch [33/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [33/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [34/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9895\n",
      "\t Batch [200/1250], Train Loss: 0.9982\n",
      "\t Batch [400/1250], Train Loss: 0.9947\n",
      "\t Batch [600/1250], Train Loss: 0.9982\n",
      "\t Batch [800/1250], Train Loss: 1.0000\n",
      "\t Batch [1000/1250], Train Loss: 1.0092\n",
      "\t Batch [1200/1250], Train Loss: 1.0083\n",
      "Epoch [34/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [34/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [35/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0048\n",
      "\t Batch [200/1250], Train Loss: 1.0034\n",
      "\t Batch [400/1250], Train Loss: 0.9977\n",
      "\t Batch [600/1250], Train Loss: 0.9965\n",
      "\t Batch [800/1250], Train Loss: 1.0061\n",
      "\t Batch [1000/1250], Train Loss: 0.9994\n",
      "\t Batch [1200/1250], Train Loss: 0.9995\n",
      "Epoch [35/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [35/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [36/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0072\n",
      "\t Batch [200/1250], Train Loss: 1.0020\n",
      "\t Batch [400/1250], Train Loss: 1.0024\n",
      "\t Batch [600/1250], Train Loss: 0.9954\n",
      "\t Batch [800/1250], Train Loss: 0.9996\n",
      "\t Batch [1000/1250], Train Loss: 1.0038\n",
      "\t Batch [1200/1250], Train Loss: 0.9954\n",
      "Epoch [36/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [36/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [37/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0032\n",
      "\t Batch [200/1250], Train Loss: 1.0007\n",
      "\t Batch [400/1250], Train Loss: 0.9937\n",
      "\t Batch [600/1250], Train Loss: 1.0045\n",
      "\t Batch [800/1250], Train Loss: 0.9979\n",
      "\t Batch [1000/1250], Train Loss: 1.0000\n",
      "\t Batch [1200/1250], Train Loss: 1.0009\n",
      "Epoch [37/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [37/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [38/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0059\n",
      "\t Batch [200/1250], Train Loss: 0.9911\n",
      "\t Batch [400/1250], Train Loss: 0.9990\n",
      "\t Batch [600/1250], Train Loss: 1.0019\n",
      "\t Batch [800/1250], Train Loss: 0.9972\n",
      "\t Batch [1000/1250], Train Loss: 0.9905\n",
      "\t Batch [1200/1250], Train Loss: 0.9983\n",
      "Epoch [38/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [38/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9998, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [39/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9965\n",
      "\t Batch [200/1250], Train Loss: 1.0065\n",
      "\t Batch [400/1250], Train Loss: 1.0025\n",
      "\t Batch [600/1250], Train Loss: 0.9911\n",
      "\t Batch [800/1250], Train Loss: 0.9992\n",
      "\t Batch [1000/1250], Train Loss: 0.9913\n",
      "\t Batch [1200/1250], Train Loss: 0.9951\n",
      "Epoch [39/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [39/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9997, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [40/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0042\n",
      "\t Batch [200/1250], Train Loss: 1.0043\n",
      "\t Batch [400/1250], Train Loss: 1.0013\n",
      "\t Batch [600/1250], Train Loss: 0.9957\n",
      "\t Batch [800/1250], Train Loss: 1.0052\n",
      "\t Batch [1000/1250], Train Loss: 0.9971\n",
      "\t Batch [1200/1250], Train Loss: 1.0019\n",
      "Epoch [40/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [40/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [41/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9963\n",
      "\t Batch [200/1250], Train Loss: 0.9977\n",
      "\t Batch [400/1250], Train Loss: 1.0017\n",
      "\t Batch [600/1250], Train Loss: 0.9989\n",
      "\t Batch [800/1250], Train Loss: 0.9978\n",
      "\t Batch [1000/1250], Train Loss: 1.0026\n",
      "\t Batch [1200/1250], Train Loss: 0.9980\n",
      "Epoch [41/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [41/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [42/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0067\n",
      "\t Batch [200/1250], Train Loss: 0.9996\n",
      "\t Batch [400/1250], Train Loss: 1.0003\n",
      "\t Batch [600/1250], Train Loss: 1.0005\n",
      "\t Batch [800/1250], Train Loss: 0.9895\n",
      "\t Batch [1000/1250], Train Loss: 1.0046\n",
      "\t Batch [1200/1250], Train Loss: 0.9947\n",
      "Epoch [42/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [42/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [43/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0012\n",
      "\t Batch [200/1250], Train Loss: 0.9904\n",
      "\t Batch [400/1250], Train Loss: 1.0006\n",
      "\t Batch [600/1250], Train Loss: 1.0022\n",
      "\t Batch [800/1250], Train Loss: 0.9981\n",
      "\t Batch [1000/1250], Train Loss: 0.9962\n",
      "\t Batch [1200/1250], Train Loss: 1.0069\n",
      "Epoch [43/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [43/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [44/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0015\n",
      "\t Batch [200/1250], Train Loss: 1.0093\n",
      "\t Batch [400/1250], Train Loss: 0.9894\n",
      "\t Batch [600/1250], Train Loss: 0.9981\n",
      "\t Batch [800/1250], Train Loss: 0.9930\n",
      "\t Batch [1000/1250], Train Loss: 1.0117\n",
      "\t Batch [1200/1250], Train Loss: 1.0139\n",
      "Epoch [44/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [44/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [45/50]:\n",
      "\t Batch [0/1250], Train Loss: 0.9982\n",
      "\t Batch [200/1250], Train Loss: 0.9947\n",
      "\t Batch [400/1250], Train Loss: 1.0033\n",
      "\t Batch [600/1250], Train Loss: 0.9938\n",
      "\t Batch [800/1250], Train Loss: 0.9935\n",
      "\t Batch [1000/1250], Train Loss: 0.9973\n",
      "\t Batch [1200/1250], Train Loss: 1.0036\n",
      "Epoch [45/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [45/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [46/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0041\n",
      "\t Batch [200/1250], Train Loss: 1.0056\n",
      "\t Batch [400/1250], Train Loss: 0.9986\n",
      "\t Batch [600/1250], Train Loss: 0.9989\n",
      "\t Batch [800/1250], Train Loss: 0.9985\n",
      "\t Batch [1000/1250], Train Loss: 1.0066\n",
      "\t Batch [1200/1250], Train Loss: 1.0023\n",
      "Epoch [46/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [46/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [47/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0059\n",
      "\t Batch [200/1250], Train Loss: 0.9954\n",
      "\t Batch [400/1250], Train Loss: 1.0018\n",
      "\t Batch [600/1250], Train Loss: 0.9901\n",
      "\t Batch [800/1250], Train Loss: 0.9955\n",
      "\t Batch [1000/1250], Train Loss: 1.0088\n",
      "\t Batch [1200/1250], Train Loss: 1.0012\n",
      "Epoch [47/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [47/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [48/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0054\n",
      "\t Batch [200/1250], Train Loss: 0.9935\n",
      "\t Batch [400/1250], Train Loss: 0.9989\n",
      "\t Batch [600/1250], Train Loss: 1.0052\n",
      "\t Batch [800/1250], Train Loss: 0.9872\n",
      "\t Batch [1000/1250], Train Loss: 1.0010\n",
      "\t Batch [1200/1250], Train Loss: 0.9839\n",
      "Epoch [48/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [48/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [49/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0003\n",
      "\t Batch [200/1250], Train Loss: 1.0076\n",
      "\t Batch [400/1250], Train Loss: 1.0156\n",
      "\t Batch [600/1250], Train Loss: 1.0041\n",
      "\t Batch [800/1250], Train Loss: 1.0094\n",
      "\t Batch [1000/1250], Train Loss: 1.0016\n",
      "\t Batch [1200/1250], Train Loss: 1.0014\n",
      "Epoch [49/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [49/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 0.9999, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Epoch [50/50]:\n",
      "\t Batch [0/1250], Train Loss: 1.0042\n",
      "\t Batch [200/1250], Train Loss: 1.0028\n",
      "\t Batch [400/1250], Train Loss: 1.0048\n",
      "\t Batch [600/1250], Train Loss: 0.9966\n",
      "\t Batch [800/1250], Train Loss: 1.0109\n",
      "\t Batch [1000/1250], Train Loss: 0.9935\n",
      "\t Batch [1200/1250], Train Loss: 0.9969\n",
      "Epoch [50/50], Validation Batch [0/179], Val Loss: 1.0000\n",
      "Epoch [50/50], Validation Batch [100/179], Val Loss: 1.0000\n",
      "Validation, Train Loss: 1.0000, Val Loss: 1.0000\n",
      "****************************************************************************************************\n",
      "Training completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SimCLRModelPipeline(\n",
       "   (encoder): SimCLR(\n",
       "     (backbone): VisionTransformer(\n",
       "       (patch_embed): PatchEmbed(\n",
       "         (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "       )\n",
       "       (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "       (rel_pos_bias): RelativePositionBias()\n",
       "       (blocks): ModuleList(\n",
       "         (0): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): Identity()\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (1): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.009)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (2): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.018)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (3): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.027)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (4): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.036)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (5): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.045)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (6): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.055)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (7): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.064)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (8): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.073)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (9): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.082)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (10): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.091)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (11): Block(\n",
       "           (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (attn): Attention(\n",
       "             (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "             (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "             (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (drop_path): DropPath(drop_prob=0.100)\n",
       "           (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): Mlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "     )\n",
       "     (fc): Sequential(\n",
       "       (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (1): ReLU()\n",
       "       (2): Dropout(p=0.1, inplace=False)\n",
       "       (3): Linear(in_features=768, out_features=512, bias=True)\n",
       "       (4): ReLU()\n",
       "       (5): Dropout(p=0.1, inplace=False)\n",
       "       (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " [1.0002423940181733,\n",
       "  1.0000394992351531,\n",
       "  0.9999905532360077,\n",
       "  0.9999064525127411,\n",
       "  1.0000090965747834,\n",
       "  0.9999341360092163,\n",
       "  0.999956057882309,\n",
       "  1.0000542838096618,\n",
       "  0.9999998987197876,\n",
       "  0.9999776753425598,\n",
       "  0.9999661828517914,\n",
       "  0.99983914270401,\n",
       "  0.9996847871303558,\n",
       "  0.9998303112506867,\n",
       "  1.0000718680858611,\n",
       "  0.9999391318798065,\n",
       "  1.0000057664871216,\n",
       "  1.0000090658187866,\n",
       "  0.9998874542713165,\n",
       "  1.000021070098877,\n",
       "  0.999916203546524,\n",
       "  0.999957232427597,\n",
       "  0.9999507296562195,\n",
       "  0.9999103506565094,\n",
       "  0.9999940400123596,\n",
       "  0.999940457201004,\n",
       "  0.9999037959575653,\n",
       "  0.9998250912666321,\n",
       "  1.0000047144889832,\n",
       "  0.9999066577911377,\n",
       "  1.0000505343914032,\n",
       "  0.9998145005226136,\n",
       "  1.0000006453514099,\n",
       "  1.0000032232284546,\n",
       "  0.9999028315544128,\n",
       "  0.9999010663509369,\n",
       "  0.9999886514663696,\n",
       "  0.9998362742900848,\n",
       "  0.9997439809322357,\n",
       "  0.9998766983032227,\n",
       "  0.9999290113925934,\n",
       "  0.9998850827693939,\n",
       "  0.9998710935115814,\n",
       "  0.9999413753509522,\n",
       "  0.9999664890766143,\n",
       "  0.9999842744827271,\n",
       "  1.0000006300449371,\n",
       "  0.999928604221344,\n",
       "  0.9999338054180146,\n",
       "  0.9999693726062775],\n",
       " [0.9999999826846842,\n",
       "  0.9999999876794868,\n",
       "  0.9999999760249474,\n",
       "  0.9999999760249474,\n",
       "  0.9999999796878026,\n",
       "  0.999999974693,\n",
       "  0.9999999813527368,\n",
       "  0.9999999820187105,\n",
       "  0.9999999736940395,\n",
       "  0.9999999716961184,\n",
       "  0.9999999813527368,\n",
       "  0.9999999823516974,\n",
       "  0.9999999843496185,\n",
       "  0.999999976690921,\n",
       "  0.999999983017671,\n",
       "  0.9999999730280658,\n",
       "  0.9999999756919605,\n",
       "  0.9999999850155921,\n",
       "  0.9999999840166316,\n",
       "  0.9999999800207895,\n",
       "  0.9999999860145526,\n",
       "  0.9999999783558553,\n",
       "  0.9999999793548158,\n",
       "  0.9999999856815658,\n",
       "  0.9999999736940395,\n",
       "  0.9999999816857237,\n",
       "  0.999999983017671,\n",
       "  0.99999998101975,\n",
       "  0.9999999790218289,\n",
       "  0.9999999803537764,\n",
       "  0.9999999803537764,\n",
       "  0.9999999800207895,\n",
       "  0.9999999770239079,\n",
       "  0.999999976690921,\n",
       "  0.9999999790218289,\n",
       "  0.9999999796878026,\n",
       "  0.9999999710301447,\n",
       "  0.9999999806867631,\n",
       "  0.9999999720291053,\n",
       "  0.9999999756919605,\n",
       "  0.9999999826846842,\n",
       "  0.9999999730280658,\n",
       "  0.9999999740270263,\n",
       "  0.9999999803537764,\n",
       "  0.9999999733610526,\n",
       "  0.9999999793548158,\n",
       "  0.9999999730280658,\n",
       "  0.9999999716961184,\n",
       "  0.9999999846826052,\n",
       "  0.9999999743600131])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "train_dataset = MammoCompDataset(data_path = config[\"image_folder_path\"],\n",
    "                                metadata = config[\"annotation_data_path\"],\n",
    "                                phase = \"training\",\n",
    "                                datalen = config[\"data_length\"],\n",
    "                                seed=0)\n",
    "valid_dataset = MammoCompDataset(data_path = config[\"image_folder_path\"],\n",
    "                                metadata = config[\"annotation_data_path\"],\n",
    "                                phase = \"valid\",\n",
    "                                datalen = config[\"data_length\"]//7,\n",
    "                                seed=0)\n",
    "with open(config[\"model_config\"], 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "model_config = AttrDict(data)\n",
    "encoder = SimCLR(\"vit\", model_config, out_dim=config[\"embedding_dim\"])\n",
    "\n",
    "if config[\"checkpoint\"]:\n",
    "    checkpoint = torch.load(config[\"checkpoint\"])\n",
    "    print(\"Checkpoint: {}\".format(config[\"checkpoint\"]))\n",
    "    encoder.backbone.load_state_dict(checkpoint)\n",
    "SimCLR_model = SimCLRModelPipeline(encoder)\n",
    "\n",
    "train_model(model=SimCLR_model, train_dataset=train_dataset,\n",
    "            val_dataset=valid_dataset, num_epochs=config[\"num_epoch\"],\n",
    "            batch_size=config[\"batch_size\"], learning_rate=config[\"learning_rate\"],\n",
    "            checkpoint_folder=config[\"checkpoint_folder\"]\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5171624,
     "sourceId": 8636305,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5171631,
     "sourceId": 8636315,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 52328,
     "sourceId": 62694,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42240.612807,
   "end_time": "2024-06-08T14:48:55.576806",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-08T03:04:54.963999",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
